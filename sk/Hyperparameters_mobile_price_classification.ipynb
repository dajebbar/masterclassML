{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing libraries"
      ],
      "metadata": {
        "id": "HddeO7qasZ-Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IlPjxzh_qguV"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "from sklearn import model_selection, metrics\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn import tree\n",
        "from sklearn import ensemble\n",
        "import xgboost\n"
      ],
      "metadata": {
        "id": "n9TJEXhhqwvF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "8ImMPTaStsTo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fp = (\n",
        "    'https://www.kaggle.com/datasets/iabhishekofficial/'\n",
        "    'mobile-price-classification'\n",
        ")\n",
        "\n",
        "od.download(fp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIKf7d25rmH6",
        "outputId": "eacae187-e53e-400c-a05e-47a4c282a3b8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading mobile-price-classification.zip to ./mobile-price-classification\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70.6k/70.6k [00:00<00:00, 49.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('./mobile-price-classification/train.csv')\n",
        "df_test = pd.read_csv('./mobile-price-classification/test.csv')"
      ],
      "metadata": {
        "id": "a01WZGaEsm7g"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9J8UEJbs_xz",
        "outputId": "442e2624-6469-4beb-e035-06ccf8099fb6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49UfewtdtOwK",
        "outputId": "2d73563d-6407-4b0a-8993-3a7d9e55de94"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.sample(n=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "Q4wouk02teDT",
        "outputId": "897749b1-8545-4cfb-e31e-e7b74e17565c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
              "429            1048     1          0.9         0  10       1          28   \n",
              "1108            808     0          2.3         0   3       0          45   \n",
              "552             726     0          2.9         0   0       0          43   \n",
              "271             730     0          2.1         1   0       1           4   \n",
              "259            1559     1          1.6         1   6       1           6   \n",
              "125            1659     0          2.8         0   5       0          16   \n",
              "1786            930     1          0.5         1   3       1          34   \n",
              "1996           1965     1          2.6         1   0       0          39   \n",
              "\n",
              "      m_dep  mobile_wt  n_cores  pc  px_height  px_width   ram  sc_h  sc_w  \\\n",
              "429     0.8        194        2  19        966      1975  1458     5     1   \n",
              "1108    0.8        161        1   9        526      1324  3431    15     6   \n",
              "552     0.1        101        8   0        666       760  1446    17     2   \n",
              "271     0.1         89        8   2        302      1247  1210    19    15   \n",
              "259     0.5        162        6  17        179      1559  3352     9     1   \n",
              "125     0.6         89        1  20        819       902  3255    19    14   \n",
              "1786    0.5        190        4  16       1050      1726  2131     7     2   \n",
              "1996    0.2        187        4   3        915      1965  2032    11    10   \n",
              "\n",
              "      talk_time  three_g  touch_screen  wifi  price_range  \n",
              "429          15        1             0     1            1  \n",
              "1108         13        0             1     1            3  \n",
              "552           8        1             1     0            0  \n",
              "271           4        1             1     1            0  \n",
              "259           3        1             1     1            3  \n",
              "125           9        0             0     1            3  \n",
              "1786          6        1             0     1            2  \n",
              "1996         16        1             1     1            2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a67f316b-0ffc-4605-99a9-6ac0625eadf0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>battery_power</th>\n",
              "      <th>blue</th>\n",
              "      <th>clock_speed</th>\n",
              "      <th>dual_sim</th>\n",
              "      <th>fc</th>\n",
              "      <th>four_g</th>\n",
              "      <th>int_memory</th>\n",
              "      <th>m_dep</th>\n",
              "      <th>mobile_wt</th>\n",
              "      <th>n_cores</th>\n",
              "      <th>pc</th>\n",
              "      <th>px_height</th>\n",
              "      <th>px_width</th>\n",
              "      <th>ram</th>\n",
              "      <th>sc_h</th>\n",
              "      <th>sc_w</th>\n",
              "      <th>talk_time</th>\n",
              "      <th>three_g</th>\n",
              "      <th>touch_screen</th>\n",
              "      <th>wifi</th>\n",
              "      <th>price_range</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>429</th>\n",
              "      <td>1048</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>0.8</td>\n",
              "      <td>194</td>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>966</td>\n",
              "      <td>1975</td>\n",
              "      <td>1458</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1108</th>\n",
              "      <td>808</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>0.8</td>\n",
              "      <td>161</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>526</td>\n",
              "      <td>1324</td>\n",
              "      <td>3431</td>\n",
              "      <td>15</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552</th>\n",
              "      <td>726</td>\n",
              "      <td>0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>0.1</td>\n",
              "      <td>101</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>666</td>\n",
              "      <td>760</td>\n",
              "      <td>1446</td>\n",
              "      <td>17</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>730</td>\n",
              "      <td>0</td>\n",
              "      <td>2.1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>89</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>302</td>\n",
              "      <td>1247</td>\n",
              "      <td>1210</td>\n",
              "      <td>19</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>1559</td>\n",
              "      <td>1</td>\n",
              "      <td>1.6</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0.5</td>\n",
              "      <td>162</td>\n",
              "      <td>6</td>\n",
              "      <td>17</td>\n",
              "      <td>179</td>\n",
              "      <td>1559</td>\n",
              "      <td>3352</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>1659</td>\n",
              "      <td>0</td>\n",
              "      <td>2.8</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>0.6</td>\n",
              "      <td>89</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>819</td>\n",
              "      <td>902</td>\n",
              "      <td>3255</td>\n",
              "      <td>19</td>\n",
              "      <td>14</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1786</th>\n",
              "      <td>930</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>0.5</td>\n",
              "      <td>190</td>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>1050</td>\n",
              "      <td>1726</td>\n",
              "      <td>2131</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>1965</td>\n",
              "      <td>1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>0.2</td>\n",
              "      <td>187</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>915</td>\n",
              "      <td>1965</td>\n",
              "      <td>2032</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a67f316b-0ffc-4605-99a9-6ac0625eadf0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a67f316b-0ffc-4605-99a9-6ac0625eadf0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a67f316b-0ffc-4605-99a9-6ac0625eadf0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Missing values**"
      ],
      "metadata": {
        "id": "IzyeYyzKuH1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "msno.bar(df_train, figsize=(12, 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "ApnsAzHttoC7",
        "outputId": "c2586a6d-c215-471b-968c-65ba70df57ce"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1f0c3f0950>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x360 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDPTsiYuuUmR",
        "outputId": "d684e13b-b5e4-4ef9-b56c-241f89e56886"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 21 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   battery_power  2000 non-null   int64  \n",
            " 1   blue           2000 non-null   int64  \n",
            " 2   clock_speed    2000 non-null   float64\n",
            " 3   dual_sim       2000 non-null   int64  \n",
            " 4   fc             2000 non-null   int64  \n",
            " 5   four_g         2000 non-null   int64  \n",
            " 6   int_memory     2000 non-null   int64  \n",
            " 7   m_dep          2000 non-null   float64\n",
            " 8   mobile_wt      2000 non-null   int64  \n",
            " 9   n_cores        2000 non-null   int64  \n",
            " 10  pc             2000 non-null   int64  \n",
            " 11  px_height      2000 non-null   int64  \n",
            " 12  px_width       2000 non-null   int64  \n",
            " 13  ram            2000 non-null   int64  \n",
            " 14  sc_h           2000 non-null   int64  \n",
            " 15  sc_w           2000 non-null   int64  \n",
            " 16  talk_time      2000 non-null   int64  \n",
            " 17  three_g        2000 non-null   int64  \n",
            " 18  touch_screen   2000 non-null   int64  \n",
            " 19  wifi           2000 non-null   int64  \n",
            " 20  price_range    2000 non-null   int64  \n",
            "dtypes: float64(2), int64(19)\n",
            "memory usage: 328.2 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.describe().T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "kJ7npAn3usHa",
        "outputId": "0a81176b-7b7b-4d81-e5fd-5122f20ea0ee"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                count        mean          std    min      25%     50%  \\\n",
              "battery_power  2000.0  1238.51850   439.418206  501.0   851.75  1226.0   \n",
              "blue           2000.0     0.49500     0.500100    0.0     0.00     0.0   \n",
              "clock_speed    2000.0     1.52225     0.816004    0.5     0.70     1.5   \n",
              "dual_sim       2000.0     0.50950     0.500035    0.0     0.00     1.0   \n",
              "fc             2000.0     4.30950     4.341444    0.0     1.00     3.0   \n",
              "four_g         2000.0     0.52150     0.499662    0.0     0.00     1.0   \n",
              "int_memory     2000.0    32.04650    18.145715    2.0    16.00    32.0   \n",
              "m_dep          2000.0     0.50175     0.288416    0.1     0.20     0.5   \n",
              "mobile_wt      2000.0   140.24900    35.399655   80.0   109.00   141.0   \n",
              "n_cores        2000.0     4.52050     2.287837    1.0     3.00     4.0   \n",
              "pc             2000.0     9.91650     6.064315    0.0     5.00    10.0   \n",
              "px_height      2000.0   645.10800   443.780811    0.0   282.75   564.0   \n",
              "px_width       2000.0  1251.51550   432.199447  500.0   874.75  1247.0   \n",
              "ram            2000.0  2124.21300  1084.732044  256.0  1207.50  2146.5   \n",
              "sc_h           2000.0    12.30650     4.213245    5.0     9.00    12.0   \n",
              "sc_w           2000.0     5.76700     4.356398    0.0     2.00     5.0   \n",
              "talk_time      2000.0    11.01100     5.463955    2.0     6.00    11.0   \n",
              "three_g        2000.0     0.76150     0.426273    0.0     1.00     1.0   \n",
              "touch_screen   2000.0     0.50300     0.500116    0.0     0.00     1.0   \n",
              "wifi           2000.0     0.50700     0.500076    0.0     0.00     1.0   \n",
              "price_range    2000.0     1.50000     1.118314    0.0     0.75     1.5   \n",
              "\n",
              "                   75%     max  \n",
              "battery_power  1615.25  1998.0  \n",
              "blue              1.00     1.0  \n",
              "clock_speed       2.20     3.0  \n",
              "dual_sim          1.00     1.0  \n",
              "fc                7.00    19.0  \n",
              "four_g            1.00     1.0  \n",
              "int_memory       48.00    64.0  \n",
              "m_dep             0.80     1.0  \n",
              "mobile_wt       170.00   200.0  \n",
              "n_cores           7.00     8.0  \n",
              "pc               15.00    20.0  \n",
              "px_height       947.25  1960.0  \n",
              "px_width       1633.00  1998.0  \n",
              "ram            3064.50  3998.0  \n",
              "sc_h             16.00    19.0  \n",
              "sc_w              9.00    18.0  \n",
              "talk_time        16.00    20.0  \n",
              "three_g           1.00     1.0  \n",
              "touch_screen      1.00     1.0  \n",
              "wifi              1.00     1.0  \n",
              "price_range       2.25     3.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32228e84-c0b5-4469-8d35-98f45e05c1f8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>battery_power</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>1238.51850</td>\n",
              "      <td>439.418206</td>\n",
              "      <td>501.0</td>\n",
              "      <td>851.75</td>\n",
              "      <td>1226.0</td>\n",
              "      <td>1615.25</td>\n",
              "      <td>1998.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>blue</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>0.49500</td>\n",
              "      <td>0.500100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clock_speed</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>1.52225</td>\n",
              "      <td>0.816004</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2.20</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dual_sim</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>0.50950</td>\n",
              "      <td>0.500035</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fc</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>4.30950</td>\n",
              "      <td>4.341444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.00</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>four_g</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>0.52150</td>\n",
              "      <td>0.499662</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>int_memory</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>32.04650</td>\n",
              "      <td>18.145715</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.00</td>\n",
              "      <td>32.0</td>\n",
              "      <td>48.00</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>m_dep</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>0.50175</td>\n",
              "      <td>0.288416</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mobile_wt</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>140.24900</td>\n",
              "      <td>35.399655</td>\n",
              "      <td>80.0</td>\n",
              "      <td>109.00</td>\n",
              "      <td>141.0</td>\n",
              "      <td>170.00</td>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n_cores</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>4.52050</td>\n",
              "      <td>2.287837</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.00</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pc</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>9.91650</td>\n",
              "      <td>6.064315</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>10.0</td>\n",
              "      <td>15.00</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>px_height</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>645.10800</td>\n",
              "      <td>443.780811</td>\n",
              "      <td>0.0</td>\n",
              "      <td>282.75</td>\n",
              "      <td>564.0</td>\n",
              "      <td>947.25</td>\n",
              "      <td>1960.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>px_width</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>1251.51550</td>\n",
              "      <td>432.199447</td>\n",
              "      <td>500.0</td>\n",
              "      <td>874.75</td>\n",
              "      <td>1247.0</td>\n",
              "      <td>1633.00</td>\n",
              "      <td>1998.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ram</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>2124.21300</td>\n",
              "      <td>1084.732044</td>\n",
              "      <td>256.0</td>\n",
              "      <td>1207.50</td>\n",
              "      <td>2146.5</td>\n",
              "      <td>3064.50</td>\n",
              "      <td>3998.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sc_h</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>12.30650</td>\n",
              "      <td>4.213245</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.00</td>\n",
              "      <td>12.0</td>\n",
              "      <td>16.00</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sc_w</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>5.76700</td>\n",
              "      <td>4.356398</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.00</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>talk_time</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>11.01100</td>\n",
              "      <td>5.463955</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.00</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.00</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>three_g</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>0.76150</td>\n",
              "      <td>0.426273</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>touch_screen</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>0.50300</td>\n",
              "      <td>0.500116</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wifi</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>0.50700</td>\n",
              "      <td>0.500076</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>price_range</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>1.50000</td>\n",
              "      <td>1.118314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2.25</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32228e84-c0b5-4469-8d35-98f45e05c1f8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32228e84-c0b5-4469-8d35-98f45e05c1f8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32228e84-c0b5-4469-8d35-98f45e05c1f8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['price_range'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZO0IcOg7vIHv",
        "outputId": "4da0b4a1-1953-4504-8e2a-6240236c672c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    500\n",
              "2    500\n",
              "3    500\n",
              "0    500\n",
              "Name: price_range, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### separte data"
      ],
      "metadata": {
        "id": "u_B_LuMcwRxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data, target = df_train.drop(columns=['price_range']), df_train['price_range']"
      ],
      "metadata": {
        "id": "NWjoGIVvwdvz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Splitting data**"
      ],
      "metadata": {
        "id": "g5jf5xTyvwgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_dev, y_train, y_dev = model_selection.train_test_split(\n",
        "    data,\n",
        "    target,\n",
        "    test_size=.2,\n",
        "    random_state=42,\n",
        "\n",
        ")\n",
        "\n",
        "X_train.shape, y_train.shape, X_dev.shape, y_dev.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrziGJSevkek",
        "outputId": "dae1a01d-0d0a-4119-fa2d-02f0c60dfe35"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1600, 20), (1600,), (400, 20), (400,))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numerical = X_train.columns\n",
        "numerical"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-DWCUQ3w9RA",
        "outputId": "a05f2742-92ae-445e-efed-fec408f604b7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n",
              "       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n",
              "       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n",
              "       'touch_screen', 'wifi'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processor = ColumnTransformer([\n",
        "    ('sca', StandardScaler(), numerical)\n",
        "])\n",
        "\n",
        "models = [\n",
        "    DummyClassifier,\n",
        "    LogisticRegression,\n",
        "    tree.DecisionTreeClassifier,\n",
        "    ensemble.HistGradientBoostingClassifier,\n",
        "    ensemble.RandomForestClassifier,\n",
        "    xgboost.XGBClassifier,\n",
        "]\n",
        "\n",
        "model_names = [\n",
        "    'DummyClassifier',\n",
        "    'LogisticRegression',\n",
        "    'DecisionTreeClassifier',\n",
        "    'HistGradientBoostingClassifier',\n",
        "    'RandomForestClassifier',\n",
        "    'XGBClassifier',\n",
        "]\n",
        "results = {}\n",
        "\n",
        "for model in models:\n",
        "  if model == LogisticRegression:\n",
        "    cls = Pipeline([\n",
        "        ('processor',processor), \n",
        "        ('classifier', model())\n",
        "    ])\n",
        "  else:\n",
        "    cls = model()\n",
        "  \n",
        "  kfold = model_selection.KFold(\n",
        "      n_splits=10,\n",
        "      shuffle=True,\n",
        "      random_state=42,\n",
        "  )\n",
        "  cv_results = model_selection.cross_validate(\n",
        "      cls,\n",
        "      data,\n",
        "      target,\n",
        "      cv=kfold,\n",
        "      scoring='accuracy',\n",
        "      n_jobs=-1\n",
        "  )\n",
        "\n",
        "  for name in model_names:\n",
        "    results[name] = cv_results\n",
        "  \n",
        "  if model == LogisticRegression:\n",
        "    print(f\"LogisticRegression AUC: {cv_results['test_score'].mean(): .3f} \"\n",
        "          f\"+/- STD: {cv_results['test_score'].std(): .3f}\"\n",
        "    )\n",
        "\n",
        "  else:\n",
        "    print(f\"{model.__name__:22} AUC: {cv_results['test_score'].mean(): .3f} \"\n",
        "         f\"+/- STD: {cv_results['test_score'].std(): .3f}\"\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvsmR53XxO2t",
        "outputId": "80e05cc9-0312-4723-c1fd-ca2793ee5746"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DummyClassifier        AUC:  0.225 +/- STD:  0.012\n",
            "LogisticRegression AUC:  0.963 +/- STD:  0.019\n",
            "DecisionTreeClassifier AUC:  0.831 +/- STD:  0.016\n",
            "HistGradientBoostingClassifier AUC:  0.912 +/- STD:  0.017\n",
            "RandomForestClassifier AUC:  0.874 +/- STD:  0.016\n",
            "XGBClassifier          AUC:  0.907 +/- STD:  0.017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAbQN1138Jja",
        "outputId": "2303bce7-a020-4eee-c2d1-9b3472520f7d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DummyClassifier': {'fit_time': array([0.65855384, 0.64318848, 0.63045335, 0.63562155, 0.62793231,\n",
              "         0.63835859, 0.63461614, 0.63517594, 0.63386059, 0.63848782]),\n",
              "  'score_time': array([0.00427032, 0.00433278, 0.00429797, 0.00422478, 0.0046978 ,\n",
              "         0.00455785, 0.00397515, 0.00416088, 0.00396085, 0.00314879]),\n",
              "  'test_score': array([0.9  , 0.885, 0.89 , 0.92 , 0.93 , 0.89 , 0.93 , 0.93 , 0.905,\n",
              "         0.895])},\n",
              " 'LogisticRegression': {'fit_time': array([0.65855384, 0.64318848, 0.63045335, 0.63562155, 0.62793231,\n",
              "         0.63835859, 0.63461614, 0.63517594, 0.63386059, 0.63848782]),\n",
              "  'score_time': array([0.00427032, 0.00433278, 0.00429797, 0.00422478, 0.0046978 ,\n",
              "         0.00455785, 0.00397515, 0.00416088, 0.00396085, 0.00314879]),\n",
              "  'test_score': array([0.9  , 0.885, 0.89 , 0.92 , 0.93 , 0.89 , 0.93 , 0.93 , 0.905,\n",
              "         0.895])},\n",
              " 'DecisionTreeClassifier': {'fit_time': array([0.65855384, 0.64318848, 0.63045335, 0.63562155, 0.62793231,\n",
              "         0.63835859, 0.63461614, 0.63517594, 0.63386059, 0.63848782]),\n",
              "  'score_time': array([0.00427032, 0.00433278, 0.00429797, 0.00422478, 0.0046978 ,\n",
              "         0.00455785, 0.00397515, 0.00416088, 0.00396085, 0.00314879]),\n",
              "  'test_score': array([0.9  , 0.885, 0.89 , 0.92 , 0.93 , 0.89 , 0.93 , 0.93 , 0.905,\n",
              "         0.895])},\n",
              " 'HistGradientBoostingClassifier': {'fit_time': array([0.65855384, 0.64318848, 0.63045335, 0.63562155, 0.62793231,\n",
              "         0.63835859, 0.63461614, 0.63517594, 0.63386059, 0.63848782]),\n",
              "  'score_time': array([0.00427032, 0.00433278, 0.00429797, 0.00422478, 0.0046978 ,\n",
              "         0.00455785, 0.00397515, 0.00416088, 0.00396085, 0.00314879]),\n",
              "  'test_score': array([0.9  , 0.885, 0.89 , 0.92 , 0.93 , 0.89 , 0.93 , 0.93 , 0.905,\n",
              "         0.895])},\n",
              " 'RandomForestClassifier': {'fit_time': array([0.65855384, 0.64318848, 0.63045335, 0.63562155, 0.62793231,\n",
              "         0.63835859, 0.63461614, 0.63517594, 0.63386059, 0.63848782]),\n",
              "  'score_time': array([0.00427032, 0.00433278, 0.00429797, 0.00422478, 0.0046978 ,\n",
              "         0.00455785, 0.00397515, 0.00416088, 0.00396085, 0.00314879]),\n",
              "  'test_score': array([0.9  , 0.885, 0.89 , 0.92 , 0.93 , 0.89 , 0.93 , 0.93 , 0.905,\n",
              "         0.895])},\n",
              " 'XGBClassifier': {'fit_time': array([0.65855384, 0.64318848, 0.63045335, 0.63562155, 0.62793231,\n",
              "         0.63835859, 0.63461614, 0.63517594, 0.63386059, 0.63848782]),\n",
              "  'score_time': array([0.00427032, 0.00433278, 0.00429797, 0.00422478, 0.0046978 ,\n",
              "         0.00455785, 0.00397515, 0.00416088, 0.00396085, 0.00314879]),\n",
              "  'test_score': array([0.9  , 0.885, 0.89 , 0.92 , 0.93 , 0.89 , 0.93 , 0.93 , 0.905,\n",
              "         0.895])}}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper parameters tuning for best models"
      ],
      "metadata": {
        "id": "Wg0_gzcJCfCc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ** Randomized search cv**"
      ],
      "metadata": {
        "id": "KREnhHj2DKOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import loguniform\n",
        "\n",
        "\n",
        "cls = Pipeline([\n",
        "        ('processor',processor), \n",
        "        ('classifier', LogisticRegression(max_iter=1000))\n",
        "    ])\n",
        "\n",
        "best_models = [ensemble.HistGradientBoostingClassifier, cls]\n",
        "\n",
        "param_distributions = [\n",
        "    {\n",
        "        'loss': ['auto', 'categorical_crossentropy'],\n",
        "        'learning_rate': loguniform(0.001, 10),\n",
        "        'max_leaf_nodes': [2, 3, 5, 10, 15],\n",
        "        'max_depth': [1, 3, 5, 15],\n",
        "        'min_samples_leaf': [1, 2, 3, 5, 10, 20]\n",
        "    },\n",
        "    {\n",
        "        'classifier__penalty': ['none', 'l2'],\n",
        "        'classifier__C': [1.0, 2., 5, 10, 15],\n",
        "    },\n",
        "]\n",
        "\n",
        "kfold = model_selection.KFold(\n",
        "      n_splits=10,\n",
        "      shuffle=True,\n",
        "      random_state=42,\n",
        "  )\n",
        "\n",
        "model_random_search = {}\n",
        "names = ['HistGradientBoostingClassifier', 'LogisticRegression']\n",
        "\n",
        "for model, param, name in zip(best_models, param_distributions, names):\n",
        "  if name == 'HistGradientBoostingClassifier':\n",
        "    model = model()\n",
        "\n",
        "  model_random_search[name] = model_selection.RandomizedSearchCV(\n",
        "      model,\n",
        "      param_distributions=param,\n",
        "      n_iter = 20,\n",
        "      cv = kfold,\n",
        "      verbose=1,\n",
        "      n_jobs=-1,\n",
        "\n",
        "  )"
      ],
      "metadata": {
        "id": "nnR63Dh5A3dR"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, estim in model_random_search.items():\n",
        "  cv_results = model_selection.cross_validate(\n",
        "      estim,\n",
        "      data,\n",
        "      target,\n",
        "      cv=kfold,\n",
        "      n_jobs=-1,\n",
        "      return_estimator=True,\n",
        "      verbose=10,\n",
        "\n",
        "  )\n",
        "  results.append({name:cv_results})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLekhIVFIRmJ",
        "outputId": "a116526b-4b6f-400c-e0fe-473959e7febf"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   55.6s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  5.2min finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   48.3s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  1.9min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.2 s, sys: 603 ms, total: 4.8 s\n",
            "Wall time: 9min 14s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  4.1min finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, name in zip(range(len(results)), names):\n",
        "  for fold_idx, estimator in enumerate(results[i][name]['estimator']):\n",
        "    # print(results[i][name]['estimator'])\n",
        "    print(name)\n",
        "    print(f\"Best parameter found on fold #{fold_idx + 1}\")\n",
        "    print(f\"{estimator.best_params_}\")\n",
        "    print()\n",
        "    print('**-**' * 20)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fu_yl998YMQ8",
        "outputId": "21a5e9cc-31e6-4bb2-b9bb-bbaa0b6d4b2a"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HistGradientBoostingClassifier\n",
            "Best parameter found on fold #1\n",
            "{'learning_rate': 0.13014809288519916, 'loss': 'auto', 'max_depth': 3, 'max_leaf_nodes': 10, 'min_samples_leaf': 3}\n",
            "\n",
            "**-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-**\n",
            "\n",
            "HistGradientBoostingClassifier\n",
            "Best parameter found on fold #2\n",
            "{'learning_rate': 0.2939777812528601, 'loss': 'auto', 'max_depth': 5, 'max_leaf_nodes': 3, 'min_samples_leaf': 20}\n",
            "\n",
            "**-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-**\n",
            "\n",
            "HistGradientBoostingClassifier\n",
            "Best parameter found on fold #3\n",
            "{'learning_rate': 0.5316066387797617, 'loss': 'auto', 'max_depth': 3, 'max_leaf_nodes': 3, 'min_samples_leaf': 1}\n",
            "\n",
            "**-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-**\n",
            "\n",
            "HistGradientBoostingClassifier\n",
            "Best parameter found on fold #4\n",
            "{'learning_rate': 0.24498401345824417, 'loss': 'categorical_crossentropy', 'max_depth': 5, 'max_leaf_nodes': 3, 'min_samples_leaf': 1}\n",
            "\n",
            "**-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-**\n",
            "\n",
            "HistGradientBoostingClassifier\n",
            "Best parameter found on fold #5\n",
            "{'learning_rate': 0.9194709201433642, 'loss': 'categorical_crossentropy', 'max_depth': 5, 'max_leaf_nodes': 2, 'min_samples_leaf': 1}\n",
            "\n",
            "**-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-**\n",
            "\n",
            "HistGradientBoostingClassifier\n",
            "Best parameter found on fold #6\n",
            "{'learning_rate': 0.14997373143423, 'loss': 'categorical_crossentropy', 'max_depth': 3, 'max_leaf_nodes': 5, 'min_samples_leaf': 10}\n",
            "\n",
            "**-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-**\n",
            "\n",
            "HistGradientBoostingClassifier\n",
            "Best parameter found on fold #7\n",
            "{'learning_rate': 0.4611618909389636, 'loss': 'categorical_crossentropy', 'max_depth': 3, 'max_leaf_nodes': 5, 'min_samples_leaf': 2}\n",
            "\n",
            "**-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-**\n",
            "\n",
            "HistGradientBoostingClassifier\n",
            "Best parameter found on fold #8\n",
            "{'learning_rate': 0.12302260921732246, 'loss': 'categorical_crossentropy', 'max_depth': 3, 'max_leaf_nodes': 10, 'min_samples_leaf': 10}\n",
            "\n",
            "**-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-**\n",
            "\n",
            "HistGradientBoostingClassifier\n",
            "Best parameter found on fold #9\n",
            "{'learning_rate': 0.15789371879060018, 'loss': 'categorical_crossentropy', 'max_depth': 3, 'max_leaf_nodes': 5, 'min_samples_leaf': 5}\n",
            "\n",
            "**-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-**\n",
            "\n",
            "HistGradientBoostingClassifier\n",
            "Best parameter found on fold #10\n",
            "{'learning_rate': 0.617301311507652, 'loss': 'categorical_crossentropy', 'max_depth': 1, 'max_leaf_nodes': 2, 'min_samples_leaf': 5}\n",
            "\n",
            "**-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-**\n",
            "\n",
            "LogisticRegression\n",
            "Best parameter found on fold #1\n",
            "{'classifier__penalty': 'l2', 'classifier__C': 5}\n",
            "\n",
            "**-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-**\n",
            "\n",
            "LogisticRegression\n",
            "Best parameter found on fold #2\n",
            "{'classifier__penalty': 'l2', 'classifier__C': 10}\n",
            "\n",
            "**-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-**\n",
            "\n",
            "LogisticRegression\n",
            "Best parameter found on fold #3\n",
            "{'classifier__penalty': 'l2', 'classifier__C': 2.0}\n",
            "\n",
            "**-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-**\n",
            "\n",
            "LogisticRegression\n",
            "Best parameter found on fold #4\n",
            "{'classifier__penalty': 'none', 'classifier__C': 1.0}\n",
            "\n",
            "**-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-**\n",
            "\n",
            "LogisticRegression\n",
            "Best parameter found on fold #5\n",
            "{'classifier__penalty': 'l2', 'classifier__C': 15}\n",
            "\n",
            "**-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-**\n",
            "\n",
            "LogisticRegression\n",
            "Best parameter found on fold #6\n",
            "{'classifier__penalty': 'none', 'classifier__C': 1.0}\n",
            "\n",
            "**-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-**\n",
            "\n",
            "LogisticRegression\n",
            "Best parameter found on fold #7\n",
            "{'classifier__penalty': 'l2', 'classifier__C': 10}\n",
            "\n",
            "**-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-**\n",
            "\n",
            "LogisticRegression\n",
            "Best parameter found on fold #8\n",
            "{'classifier__penalty': 'l2', 'classifier__C': 15}\n",
            "\n",
            "**-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-**\n",
            "\n",
            "LogisticRegression\n",
            "Best parameter found on fold #9\n",
            "{'classifier__penalty': 'l2', 'classifier__C': 10}\n",
            "\n",
            "**-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-**\n",
            "\n",
            "LogisticRegression\n",
            "Best parameter found on fold #10\n",
            "{'classifier__penalty': 'l2', 'classifier__C': 15}\n",
            "\n",
            "**-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-****-**\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can constat that we obtain models with unstable hyperparameters."
      ],
      "metadata": {
        "id": "F92M3GUvo9zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_distributions_histgrad = {\n",
        "        'loss': ['auto', 'categorical_crossentropy'],\n",
        "        'learning_rate': loguniform(0.001, 10),\n",
        "        'max_leaf_nodes': [2, 3, 5, 10, 15],\n",
        "        'max_depth': [1, 3, 5, 15],\n",
        "        'min_samples_leaf': [1, 2, 3, 5, 10, 20]\n",
        "    }\n",
        "\n",
        "classifier_histgrad = ensemble.HistGradientBoostingClassifier()\n",
        "\n",
        "model_histgrad = model_selection.RandomizedSearchCV(\n",
        "    classifier_histgrad,\n",
        "    param_distributions=param_distributions_histgrad,\n",
        "    n_iter=20,\n",
        "    scoring='accuracy',\n",
        "    verbose=10,\n",
        "    cv=kfold,\n",
        "    n_jobs=-1,\n",
        "    error_score='raise'\n",
        "\n",
        ").fit(X_train, y_train)\n",
        "\n",
        "print(f\"best score: {model_histgrad.best_score_}\")\n",
        "print('best parameters set: ')\n",
        "best_parameters = model_histgrad.best_estimator_.get_params()\n",
        "\n",
        "for param_name in sorted(param_distributions_histgrad.keys()):\n",
        "  print(f\"\\t {param_name}: {best_parameters[param_name]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOz2-qLeeubJ",
        "outputId": "3e69fe11-22d0-4b5f-f833-8f8df27cd8b8"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
            "best score: 0.92125\n",
            "best parameters set: \n",
            "\t learning_rate: 0.1978294144382018\n",
            "\t loss: auto\n",
            "\t max_depth: 5\n",
            "\t max_leaf_nodes: 5\n",
            "\t min_samples_leaf: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_distributions_log_reg = {\n",
        "    'classifier__penalty': ['l2', 'none'],\n",
        "    'classifier__C': [1.0, 2., 5, 10, 15],\n",
        "}\n",
        "\n",
        "cls = Pipeline([\n",
        "        ('processor',processor), \n",
        "        ('classifier', LogisticRegression(max_iter=250))\n",
        "    ])\n",
        "\n",
        "model_logreg = model_selection.RandomizedSearchCV(\n",
        "    cls,\n",
        "    param_distributions=param_distributions_log_reg,\n",
        "    n_iter=20,\n",
        "    scoring='accuracy',\n",
        "    verbose=10,\n",
        "    cv=kfold,\n",
        "    n_jobs=-1,\n",
        "    error_score='raise'\n",
        "\n",
        ").fit(X_train, y_train)\n",
        "\n",
        "print(f\"best score: {model_logreg.best_score_}\")\n",
        "print('best parameters set: ')\n",
        "best_parameters = model_logreg.best_estimator_.get_params()\n",
        "\n",
        "for param_name in sorted(param_distributions_log_reg.keys()):\n",
        "  print(f\"\\t {param_name}: {best_parameters[param_name]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFlFEU2ssMgk",
        "outputId": "db50e6c8-f387-4a1b-bb54-de5f553d4cb3"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 10 is smaller than n_iter=20. Running 10 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
            "best score: 0.9662499999999999\n",
            "best parameters set: \n",
            "\t classifier__C: 1.0\n",
            "\t classifier__penalty: none\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters Using Bayesian optimization with gaussian process"
      ],
      "metadata": {
        "id": "ss_OdJ4J1wS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/scikit-optimize/scikit-optimize.git --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vL2pjvRy2F6n",
        "outputId": "a38affd6-9d52-4da2-d041-91f6d87e7cf8"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for scikit-optimize (PEP 517) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "from skopt import gp_minimize, space\n",
        "\n",
        "\n",
        "def optimize(params, param_names, x, y):\n",
        "  \"\"\" \n",
        "  The main optimization function.\n",
        "  This function takes all the arguments from the search space\n",
        "  and training features and targets. It then initializes\n",
        "  the models by setting the chosen parameters and runs\n",
        "  cross-validation and returns a negative accuracy score\n",
        "  :param params: list of params from gp_minimize\n",
        "  :param param_names: list of param names. order is important!\n",
        "  :param x: training data\n",
        "  :param y: labels/targets\n",
        "  :return: negative accuracy after 10 folds\n",
        "  \"\"\"\n",
        "\n",
        "  # convert params to dictionary\n",
        "  params = dict(zip(param_names, params))\n",
        "\n",
        "  # initialize model with current parameters\n",
        "  model = ensemble.HistGradientBoostingClassifier(**params)\n",
        "\n",
        "  # initialize k-fold\n",
        "  kf = model_selection.KFold(n_splits=10)\n",
        "\n",
        "  # initialize accuracy list\n",
        "  accuracies = []\n",
        "\n",
        "  # loop over all folds\n",
        "  for idx in kf.split(X=x, y=y):\n",
        "    train_idx, dev_idx = idx[0], idx[1]\n",
        "    xtrain = x[train_idx]\n",
        "    ytrain = y[train_idx]\n",
        "\n",
        "    xdev = x[dev_idx]\n",
        "    ydev = y[dev_idx]\n",
        "\n",
        "    # fit model for current fold\n",
        "    model.fit(xtrain, ytrain)\n",
        "\n",
        "    #create predictions\n",
        "    preds = model.predict(xdev)\n",
        "\n",
        "    # calculate and append accuracy\n",
        "    fold_accuracy = metrics.accuracy_score(ydev, preds)\n",
        "    accuracies.append(fold_accuracy)\n",
        "\n",
        "    # return negative accuracy\n",
        "    return -1 * np.mean(accuracies)"
      ],
      "metadata": {
        "id": "Rip3qpngxhNR"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# param_distributions_histgrad = {\n",
        "#         'loss': ['auto', 'categorical_crossentropy'],\n",
        "#         'learning_rate': loguniform(0.001, 10),\n",
        "#         'max_leaf_nodes': [2, 3, 5, 10, 15],\n",
        "#         'max_depth': [1, 3, 5, 15],\n",
        "#         'min_samples_leaf': [1, 2, 3, 5, 10, 20]\n",
        "#     }\n",
        "# define a parameter space for HistGradientboostingClassifier\n",
        "\n",
        "param_space = [\n",
        "    # loss is a category. here we define list of categories\n",
        "    space.Categorical(['auto', 'categorical_crossentropy'], name='loss'),\n",
        "    space.Real(0.001, 10, prior='uniform', name='learning_rate'),\n",
        "    space.Integer(2, 15, name='max_leaf_nodes'),\n",
        "    space.Integer(1, 15, name='max_depth'),\n",
        "    space.Integer(1, 20, name='min_samples_leaf'),\n",
        "]\n",
        "\n",
        "# make a list of param names\n",
        "# this has to be same order as the search space\n",
        "# inside the main function\n",
        "param_names = [\n",
        "    'loss',\n",
        "    'learning_rate',\n",
        "    'max_leaf_nodes',\n",
        "    'max_depth',\n",
        "    'min_samples_leaf'\n",
        "]\n",
        "\n",
        "# by using functools partial, i am creating a\n",
        "# new function which has same parameters as the\n",
        "# optimize function except for the fact that\n",
        "# only one param, i.e. the \"params\" parameter is\n",
        "# required. this is how gp_minimize expects the\n",
        "# optimization function to be. you can get rid of this\n",
        "# by reading data inside the optimize function or by\n",
        "# defining the optimize function here.\n",
        "optimization_function = partial(\n",
        "    optimize,\n",
        "    param_names=param_names,\n",
        "    x=X_train.values,\n",
        "    y=y_train.values,\n",
        ")\n",
        "\n",
        "# now we call gp_minimize from scikit-optimize\n",
        "# gp_minimize uses bayesian optimization for\n",
        "# minimization of the optimization function.\n",
        "# we need a space of parameters, the function itself,\n",
        "# the number of calls/iterations we want to have\n",
        "result = gp_minimize(\n",
        "    optimization_function,\n",
        "    dimensions=param_space,\n",
        "    n_calls=15,\n",
        "    n_random_starts=10,\n",
        "    verbose=10\n",
        ")\n",
        "\n",
        "# create best params dict and print it\n",
        "best_params = dict(zip(param_names, result.x))\n",
        "print(best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-dTvt_A6pav",
        "outputId": "a62e876b-ec5c-43a4-b10f-699fe7a362a3"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration No: 1 started. Evaluating function at random point.\n",
            "Iteration No: 1 ended. Evaluation done at random point.\n",
            "Time taken: 0.1088\n",
            "Function value obtained: -0.2188\n",
            "Current minimum: -0.2188\n",
            "Iteration No: 2 started. Evaluating function at random point.\n",
            "Iteration No: 2 ended. Evaluation done at random point.\n",
            "Time taken: 0.2823\n",
            "Function value obtained: -0.7562\n",
            "Current minimum: -0.7562\n",
            "Iteration No: 3 started. Evaluating function at random point.\n",
            "Iteration No: 3 ended. Evaluation done at random point.\n",
            "Time taken: 0.1325\n",
            "Function value obtained: -0.3625\n",
            "Current minimum: -0.7562\n",
            "Iteration No: 4 started. Evaluating function at random point.\n",
            "Iteration No: 4 ended. Evaluation done at random point.\n",
            "Time taken: 0.1455\n",
            "Function value obtained: -0.3438\n",
            "Current minimum: -0.7562\n",
            "Iteration No: 5 started. Evaluating function at random point.\n",
            "Iteration No: 5 ended. Evaluation done at random point.\n",
            "Time taken: 0.1160\n",
            "Function value obtained: -0.4938\n",
            "Current minimum: -0.7562\n",
            "Iteration No: 6 started. Evaluating function at random point.\n",
            "Iteration No: 6 ended. Evaluation done at random point.\n",
            "Time taken: 0.1213\n",
            "Function value obtained: -0.1062\n",
            "Current minimum: -0.7562\n",
            "Iteration No: 7 started. Evaluating function at random point.\n",
            "Iteration No: 7 ended. Evaluation done at random point.\n",
            "Time taken: 0.2687\n",
            "Function value obtained: -0.5938\n",
            "Current minimum: -0.7562\n",
            "Iteration No: 8 started. Evaluating function at random point.\n",
            "Iteration No: 8 ended. Evaluation done at random point.\n",
            "Time taken: 0.1321\n",
            "Function value obtained: -0.4250\n",
            "Current minimum: -0.7562\n",
            "Iteration No: 9 started. Evaluating function at random point.\n",
            "Iteration No: 9 ended. Evaluation done at random point.\n",
            "Time taken: 0.1133\n",
            "Function value obtained: -0.0312\n",
            "Current minimum: -0.7562\n",
            "Iteration No: 10 started. Evaluating function at random point.\n",
            "Iteration No: 10 ended. Evaluation done at random point.\n",
            "Time taken: 0.5700\n",
            "Function value obtained: -0.1375\n",
            "Current minimum: -0.7562\n",
            "Iteration No: 11 started. Searching for the next optimal point.\n",
            "Iteration No: 11 ended. Search finished for the next optimal point.\n",
            "Time taken: 0.9552\n",
            "Function value obtained: -0.6813\n",
            "Current minimum: -0.7562\n",
            "Iteration No: 12 started. Searching for the next optimal point.\n",
            "Iteration No: 12 ended. Search finished for the next optimal point.\n",
            "Time taken: 0.7123\n",
            "Function value obtained: -0.8812\n",
            "Current minimum: -0.8812\n",
            "Iteration No: 13 started. Searching for the next optimal point.\n",
            "Iteration No: 13 ended. Search finished for the next optimal point.\n",
            "Time taken: 0.7105\n",
            "Function value obtained: -0.6813\n",
            "Current minimum: -0.8812\n",
            "Iteration No: 14 started. Searching for the next optimal point.\n",
            "Iteration No: 14 ended. Search finished for the next optimal point.\n",
            "Time taken: 0.8500\n",
            "Function value obtained: -0.7562\n",
            "Current minimum: -0.8812\n",
            "Iteration No: 15 started. Searching for the next optimal point.\n",
            "Iteration No: 15 ended. Search finished for the next optimal point.\n",
            "Time taken: 0.6491\n",
            "Function value obtained: -0.2062\n",
            "Current minimum: -0.8812\n",
            "{'loss': 'categorical_crossentropy', 'learning_rate': 0.40196146019989565, 'max_leaf_nodes': 2, 'max_depth': 1, 'min_samples_leaf': 20}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems like we have decreasing accuracy from 0.92 with randomized search cv to 0.88 with bayesian optimisation."
      ],
      "metadata": {
        "id": "zaEDOrdPDKwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "from skopt import gp_minimize, space\n",
        "\n",
        "\n",
        "def optimize(params, param_names, x, y):\n",
        "  \"\"\" \n",
        "  The main optimization function.\n",
        "  This function takes all the arguments from the search space\n",
        "  and training features and targets. It then initializes\n",
        "  the models by setting the chosen parameters and runs\n",
        "  cross-validation and returns a negative accuracy score\n",
        "  :param params: list of params from gp_minimize\n",
        "  :param param_names: list of param names. order is important!\n",
        "  :param x: training data\n",
        "  :param y: labels/targets\n",
        "  :return: negative accuracy after 10 folds\n",
        "  \"\"\"\n",
        "\n",
        "  # convert params to dictionary\n",
        "  params = dict(zip(param_names, params))\n",
        "\n",
        "  # initialize model with current parameters\n",
        "  model = LogisticRegression(**params)\n",
        "\n",
        "  # initialize k-fold\n",
        "  kf = model_selection.KFold(n_splits=10)\n",
        "\n",
        "  # initialize accuracy list\n",
        "  accuracies = []\n",
        "\n",
        "  # loop over all folds\n",
        "  for idx in kf.split(X=x, y=y):\n",
        "    train_idx, dev_idx = idx[0], idx[1]\n",
        "    xtrain = x[train_idx]\n",
        "    ytrain = y[train_idx]\n",
        "\n",
        "    xdev = x[dev_idx]\n",
        "    ydev = y[dev_idx]\n",
        "\n",
        "    # fit model for current fold\n",
        "    model.fit(xtrain, ytrain)\n",
        "\n",
        "    #create predictions\n",
        "    preds = model.predict(xdev)\n",
        "\n",
        "    # calculate and append accuracy\n",
        "    fold_accuracy = metrics.accuracy_score(ydev, preds)\n",
        "    accuracies.append(fold_accuracy)\n",
        "\n",
        "    # return negative accuracy\n",
        "    return -1 * np.mean(accuracies)"
      ],
      "metadata": {
        "id": "QaUNTfXl-Utp"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_sca = X_train.copy()\n",
        "X_dev_sca = X_dev.copy()\n",
        "\n",
        "sca = StandardScaler()\n",
        "X_train_sca = sca.fit_transform(X_train_sca)\n",
        "X_train_sca = pd.DataFrame(X_train_sca, columns=X_train.columns)\n",
        "X_dev_sca = sca.transform(X_dev_sca)\n",
        "X_dev_sca = pd.DataFrame(X_dev_sca, columns=X_dev.columns)\n",
        "\n",
        "X_dev_sca.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "N99vJ115IQ32",
        "outputId": "8bba32d3-6cf7-4884-8448-523024453d3f"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   battery_power      blue  clock_speed  dual_sim        fc    four_g  \\\n",
              "0       0.919657 -0.981423     1.202995 -1.030464 -0.301987  0.955968   \n",
              "1      -0.133477 -0.981423    -1.236230 -1.030464  0.620111  0.955968   \n",
              "\n",
              "   int_memory     m_dep  mobile_wt   n_cores        pc  px_height  px_width  \\\n",
              "0   -0.399682  0.339750   1.680472 -1.110623 -0.811268  -0.972891  0.831970   \n",
              "1   -1.334288 -0.008935  -0.074553  1.510316  1.018112  -0.829167 -0.609863   \n",
              "\n",
              "        ram      sc_h      sc_w  talk_time   three_g  touch_screen      wifi  \n",
              "0 -1.323738 -1.003792  0.067867   0.007832  0.557137      0.990050 -0.997503  \n",
              "1  0.413624  1.612728  2.603886   1.460787  0.557137     -1.010051 -0.997503  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c33d2176-ba7f-4572-868d-72deff6dfda4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>battery_power</th>\n",
              "      <th>blue</th>\n",
              "      <th>clock_speed</th>\n",
              "      <th>dual_sim</th>\n",
              "      <th>fc</th>\n",
              "      <th>four_g</th>\n",
              "      <th>int_memory</th>\n",
              "      <th>m_dep</th>\n",
              "      <th>mobile_wt</th>\n",
              "      <th>n_cores</th>\n",
              "      <th>pc</th>\n",
              "      <th>px_height</th>\n",
              "      <th>px_width</th>\n",
              "      <th>ram</th>\n",
              "      <th>sc_h</th>\n",
              "      <th>sc_w</th>\n",
              "      <th>talk_time</th>\n",
              "      <th>three_g</th>\n",
              "      <th>touch_screen</th>\n",
              "      <th>wifi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.919657</td>\n",
              "      <td>-0.981423</td>\n",
              "      <td>1.202995</td>\n",
              "      <td>-1.030464</td>\n",
              "      <td>-0.301987</td>\n",
              "      <td>0.955968</td>\n",
              "      <td>-0.399682</td>\n",
              "      <td>0.339750</td>\n",
              "      <td>1.680472</td>\n",
              "      <td>-1.110623</td>\n",
              "      <td>-0.811268</td>\n",
              "      <td>-0.972891</td>\n",
              "      <td>0.831970</td>\n",
              "      <td>-1.323738</td>\n",
              "      <td>-1.003792</td>\n",
              "      <td>0.067867</td>\n",
              "      <td>0.007832</td>\n",
              "      <td>0.557137</td>\n",
              "      <td>0.990050</td>\n",
              "      <td>-0.997503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.133477</td>\n",
              "      <td>-0.981423</td>\n",
              "      <td>-1.236230</td>\n",
              "      <td>-1.030464</td>\n",
              "      <td>0.620111</td>\n",
              "      <td>0.955968</td>\n",
              "      <td>-1.334288</td>\n",
              "      <td>-0.008935</td>\n",
              "      <td>-0.074553</td>\n",
              "      <td>1.510316</td>\n",
              "      <td>1.018112</td>\n",
              "      <td>-0.829167</td>\n",
              "      <td>-0.609863</td>\n",
              "      <td>0.413624</td>\n",
              "      <td>1.612728</td>\n",
              "      <td>2.603886</td>\n",
              "      <td>1.460787</td>\n",
              "      <td>0.557137</td>\n",
              "      <td>-1.010051</td>\n",
              "      <td>-0.997503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c33d2176-ba7f-4572-868d-72deff6dfda4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c33d2176-ba7f-4572-868d-72deff6dfda4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c33d2176-ba7f-4572-868d-72deff6dfda4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# define a parameter space for LogisticRegressionClassifier\n",
        "\n",
        "param_space = [\n",
        "    space.Integer(1, 15, name='C'),\n",
        "    space.Categorical(['l2', 'none'], name='penalty'),\n",
        "]\n",
        "\n",
        "# make a list of param names\n",
        "# this has to be same order as the search space\n",
        "# inside the main function\n",
        "param_names = [\n",
        "    'C',\n",
        "    'penalty',\n",
        "]\n",
        "\n",
        "# by using functools partial, i am creating a\n",
        "# new function which has same parameters as the\n",
        "# optimize function except for the fact that\n",
        "# only one param, i.e. the \"params\" parameter is\n",
        "# required. this is how gp_minimize expects the\n",
        "# optimization function to be. you can get rid of this\n",
        "# by reading data inside the optimize function or by\n",
        "# defining the optimize function here.\n",
        "optimization_function = partial(\n",
        "    optimize,\n",
        "    param_names=param_names,\n",
        "    x=X_train_sca.values,\n",
        "    y=y_train.values,\n",
        ")\n",
        "\n",
        "# now we call gp_minimize from scikit-optimize\n",
        "# gp_minimize uses bayesian optimization for\n",
        "# minimization of the optimization function.\n",
        "# we need a space of parameters, the function itself,\n",
        "# the number of calls/iterations we want to have\n",
        "result = gp_minimize(\n",
        "    optimization_function,\n",
        "    dimensions=param_space,\n",
        "    n_calls=15,\n",
        "    n_random_starts=10,\n",
        "    verbose=10\n",
        ")\n",
        "\n",
        "# create best params dict and print it\n",
        "best_params = dict(zip(param_names, result.x))\n",
        "print(best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-H7SMT7DxVE",
        "outputId": "6198b60d-9081-494e-b68f-f7e9bb6f268b"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration No: 1 started. Evaluating function at random point.\n",
            "Iteration No: 1 ended. Evaluation done at random point.\n",
            "Time taken: 0.0754\n",
            "Function value obtained: -0.9500\n",
            "Current minimum: -0.9500\n",
            "Iteration No: 2 started. Evaluating function at random point.\n",
            "Iteration No: 2 ended. Evaluation done at random point.\n",
            "Time taken: 0.0724\n",
            "Function value obtained: -0.9500\n",
            "Current minimum: -0.9500\n",
            "Iteration No: 3 started. Evaluating function at random point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration No: 3 ended. Evaluation done at random point.\n",
            "Time taken: 0.0835\n",
            "Function value obtained: -0.9500\n",
            "Current minimum: -0.9500\n",
            "Iteration No: 4 started. Evaluating function at random point.\n",
            "Iteration No: 4 ended. Evaluation done at random point.\n",
            "Time taken: 0.0739\n",
            "Function value obtained: -0.9500\n",
            "Current minimum: -0.9500\n",
            "Iteration No: 5 started. Evaluating function at random point.\n",
            "Iteration No: 5 ended. Evaluation done at random point.\n",
            "Time taken: 0.0692\n",
            "Function value obtained: -0.9500\n",
            "Current minimum: -0.9500\n",
            "Iteration No: 6 started. Evaluating function at random point.\n",
            "Iteration No: 6 ended. Evaluation done at random point.\n",
            "Time taken: 0.0518\n",
            "Function value obtained: -0.9437\n",
            "Current minimum: -0.9500\n",
            "Iteration No: 7 started. Evaluating function at random point.\n",
            "Iteration No: 7 ended. Evaluation done at random point.\n",
            "Time taken: 0.0407\n",
            "Function value obtained: -0.9375\n",
            "Current minimum: -0.9500\n",
            "Iteration No: 8 started. Evaluating function at random point.\n",
            "Iteration No: 8 ended. Evaluation done at random point.\n",
            "Time taken: 0.0311\n",
            "Function value obtained: -0.9187\n",
            "Current minimum: -0.9500\n",
            "Iteration No: 9 started. Evaluating function at random point.\n",
            "Iteration No: 9 ended. Evaluation done at random point.\n",
            "Time taken: 0.0835\n",
            "Function value obtained: -0.9500\n",
            "Current minimum: -0.9500\n",
            "Iteration No: 10 started. Evaluating function at random point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration No: 10 ended. Evaluation done at random point.\n",
            "Time taken: 0.3786\n",
            "Function value obtained: -0.9500\n",
            "Current minimum: -0.9500\n",
            "Iteration No: 11 started. Searching for the next optimal point.\n",
            "Iteration No: 11 ended. Search finished for the next optimal point.\n",
            "Time taken: 0.3226\n",
            "Function value obtained: -0.9437\n",
            "Current minimum: -0.9500\n",
            "Iteration No: 12 started. Searching for the next optimal point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration No: 12 ended. Search finished for the next optimal point.\n",
            "Time taken: 0.3966\n",
            "Function value obtained: -0.9500\n",
            "Current minimum: -0.9500\n",
            "Iteration No: 13 started. Searching for the next optimal point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration No: 13 ended. Search finished for the next optimal point.\n",
            "Time taken: 0.5034\n",
            "Function value obtained: -0.9500\n",
            "Current minimum: -0.9500\n",
            "Iteration No: 14 started. Searching for the next optimal point.\n",
            "Iteration No: 14 ended. Search finished for the next optimal point.\n",
            "Time taken: 0.3588\n",
            "Function value obtained: -0.9500\n",
            "Current minimum: -0.9500\n",
            "Iteration No: 15 started. Searching for the next optimal point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration No: 15 ended. Search finished for the next optimal point.\n",
            "Time taken: 0.3935\n",
            "Function value obtained: -0.9500\n",
            "Current minimum: -0.9500\n",
            "{'C': 13, 'penalty': 'none'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ik3-7J_1HAHl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}